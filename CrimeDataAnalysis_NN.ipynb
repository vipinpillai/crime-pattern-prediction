{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "\n",
    "bpd_crime_dataframe = pd.read_csv('BPD_Crime_sanitized.csv')\n",
    "bpd_crime_dataframe = bpd_crime_dataframe.ix[~bpd_crime_dataframe.CrimeCode.isin(['8DO', '3LK', '6K', '8FV', '8CV', '3N', '8GV', '8EV', '3EO', '8I', '8CO', '8BV', '8GO', '3EK', '3LO', '3GO'])]\n",
    "\n",
    "bpd_crime_dataframe =  bpd_crime_dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#X = pd.concat([pd.get_dummies(bpd_crime_dataframe['Weapon'], prefix = 'W'), pd.get_dummies(bpd_crime_dataframe['CrimeHour'], prefix = 'CH'), pd.get_dummies(bpd_crime_dataframe['CrimeDay'], prefix = 'CD')], axis = 1)\n",
    "X = pd.concat([pd.get_dummies(bpd_crime_dataframe['Weapon'], prefix = 'W')], axis = 1)\n",
    "Y = bpd_crime_dataframe['CrimeCode']\n",
    "## Accuracy = 76.62%\n",
    "\n",
    "#X_train = X.iloc[1:(len(X)/2)]\n",
    "#X_test = X.iloc[(len(X)/2) + 1: len(X)]\n",
    "#Y_train = Y.iloc[1:(len(Y)/2)]\n",
    "#Y_test = Y.iloc[(len(Y)/2) + 1: len(Y)]\n",
    "\n",
    "X_train = X[1:10000]\n",
    "Y_train = Y[1:10000]\n",
    "X_test = X[10000:20000]\n",
    "Y_test = Y[10000:20000]\n",
    "\n",
    "#print len(Y_train.unique()), ' & ', len(Y_test.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9999/9999 [==============================] - 2s - loss: 1.9221 - acc: 0.4924     \n",
      "Epoch 2/20\n",
      "9999/9999 [==============================] - 2s - loss: 1.3724 - acc: 0.5359     \n",
      "Epoch 3/20\n",
      "9999/9999 [==============================] - 1s - loss: 1.2559 - acc: 0.6119     \n",
      "Epoch 4/20\n",
      "9999/9999 [==============================] - 1s - loss: 1.1710 - acc: 0.6119     \n",
      "Epoch 5/20\n",
      "9999/9999 [==============================] - 2s - loss: 1.1010 - acc: 0.6364     \n",
      "Epoch 6/20\n",
      "9999/9999 [==============================] - 1s - loss: 1.0460 - acc: 0.6839     \n",
      "Epoch 7/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.9984 - acc: 0.7334     \n",
      "Epoch 8/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.9553 - acc: 0.7612     \n",
      "Epoch 9/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.9192 - acc: 0.7616     \n",
      "Epoch 10/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.8753 - acc: 0.7616     \n",
      "Epoch 11/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.8331 - acc: 0.7616     \n",
      "Epoch 12/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.8111 - acc: 0.7616     \n",
      "Epoch 13/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.7923 - acc: 0.7616     \n",
      "Epoch 14/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.7796 - acc: 0.7616     \n",
      "Epoch 15/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.7674 - acc: 0.7616     \n",
      "Epoch 16/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.7614 - acc: 0.7616     \n",
      "Epoch 17/20\n",
      "9999/9999 [==============================] - 2s - loss: 0.7570 - acc: 0.7616     \n",
      "Epoch 18/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.7537 - acc: 0.7616     \n",
      "Epoch 19/20\n",
      "9999/9999 [==============================] - 1s - loss: 0.7523 - acc: 0.7616     \n",
      "Epoch 20/20\n",
      "9999/9999 [==============================] - 2s - loss: 0.7504 - acc: 0.7616     \n",
      "10000/10000 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.73041131758317346, 0.76629999999999998]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model(input_size, output_size):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size, input_dim=input_size, init='uniform', activation='relu'))\n",
    "    model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dense(input_size, input_dim=input_size, init='uniform', activation='relu'))\n",
    "    #model.add(LeakyReLU(alpha=0.001))\n",
    "    model.add(Dense(output_size, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "build_fn = baseline_model(len(X_train.columns), len(Y.unique()))\n",
    "build_fn.fit(X_train.values, dummy_y_train, batch_size=5, nb_epoch = 20, verbose=1, shuffle=True)\n",
    "build_fn.evaluate(X_test.values, dummy_y_test, batch_size=5, verbose=1)\n",
    "\n",
    "#estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=15, batch_size=5, verbose=1)\n",
    "#kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, X.values, dummy_y, cv=kfold)\n",
    "#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# X_predict = pd.concat([pd.get_dummies(test_crime_dataframe['Neighborhood'], prefix = 'NB'), pd.get_dummies(test_crime_dataframe['District'], prefix = 'DS'), pd.get_dummies(test_crime_dataframe['Inside/Outside'], prefix = 'IO'), pd.get_dummies(test_crime_dataframe['Weapon'], prefix = 'W'), pd.get_dummies(test_crime_dataframe['CrimeHour'], prefix = 'CH'), pd.get_dummies(test_crime_dataframe['CrimeDay'], prefix = 'CD')], axis = 1)\n",
    "# Y = train_crime_dataframe['CrimeCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
